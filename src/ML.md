### Machine Learning Interview

| Terminology                                    | Explanation                                                  |
| ---------------------------------------------- | ------------------------------------------------------------ |
| ROC/PRC/AUC                                    | https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python<br />https://blog.csdn.net/pzy20062141/article/details/48711355 |
| L1/L2                                          | https://towardsdatascience.com/l1-and-l2-regularization-methods-ce25e7fc831c |
| Loss Function/Cost Function/Objection Function | https://stats.stackexchange.com/questions/179026/objective-function-cost-function-loss-function-are-they-the-same-thing |
| Logistic Loss                                  | https://en.wikipedia.org/wiki/Loss_functions_for_classification#Logistic_loss |
| Factorization Machine                          | https://www.cnblogs.com/pinard/p/6370127.html<br />https://tracholar.github.io/machine-learning/2017/03/10/factorization-machine.html |
| Feature Scaling                                | https://www.cnblogs.com/ooon/p/4947347.html<br />https://www.tinymind.cn/articles/1217 |
| SVD                                            | https://blog.csdn.net/zhongkejingwang/article/details/43053513<br />https://charlesliuyx.github.io/2017/10/06/%E3%80%90%E7%9B%B4%E8%A7%82%E8%AF%A6%E8%A7%A3%E3%80%91%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E7%9A%84%E6%9C%AC%E8%B4%A8 |
| Linear Discriminant Analysis                   | http://www.sci.utah.edu/~shireen/pdfs/tutorials/Elhabian_LDA09.pdf |
| Lagrangian Duality                             | https://www.zhihu.com/question/58584814/answer/159863739<br />http://luojinping.com/2018/03/04/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95/ |
| XGBoost                                        | https://xgboost.readthedocs.io/en/latest/tutorials/model.html<br />http://wepon.me/files/gbdt.pdf |
| XGB/LGBM                                       | https://datascience.stackexchange.com/questions/26699/decision-trees-leaf-wise-best-first-and-level-wise-tree-traverse |
| Regularization                                 | http://statweb.stanford.edu/~tibs/sta305files/Rudyregularization.pdf |
| SGD/Momentum/Adagard/Adam                      | https://zh.d2l.ai/chapter_optimization/index.html            |
| L1不可导                                       | https://blog.csdn.net/xiaocong1990/article/details/83039802<br />https://www.zhihu.com/question/38426074 |
| 时间序列交叉验证                               | https://lonepatient.top/2018/06/10/time-series-nested-cross-validation.html |
| 方差偏差的分解公式                             | https://blog.csdn.net/qq_32742009/article/details/82142119   |
| 类别不平衡                                     | https://www.zhihu.com/question/269698662<br />https://www.rogoso.info/oversampling-and-undersampling/<br />https://blog.csdn.net/shenxiaoming77/article/details/72616333 |
| 过拟合的解决方法                               | https://www.zhihu.com/question/59201590                      |
| 特征工程                                       | https://www.zhihu.com/question/29316149                      |
| 迭代器和生成器                                 | https://github.com/taizilongxu/interview_python#9-%E8%BF%AD%E4%BB%A3%E5%99%A8%E5%92%8C%E7%94%9F%E6%88%90%E5%99%A8<br />https://foofish.net/iterators-vs-generators.html |
| Python闭包                                     | https://foofish.net/python-closure.html                      |
| EM                                             | https://snaildove.github.io/2018/10/01/9.EM_and_GEM_LiHang-Statistical-Learning-Methods/ |
| Softmax/交叉熵                                 | http://zh.d2l.ai/chapter_deep-learning-basics/softmax-regression.html |
| 激活函数                                       | http://zh.d2l.ai/chapter_deep-learning-basics/mlp.html       |
| k-means/mapreduce                              | https://blog.csdn.net/asn_forever/article/details/81233547<br />http://blog.taohuawu.club/article/20 |

